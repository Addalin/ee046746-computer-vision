{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <img src=\"https://img.icons8.com/bubbles/100/000000/3d-glasses.png\" style=\"height:50px;display:inline\"> EE 046746 - Technion - Computer Vision\n",
    "\n",
    "#### Dahlia Urbach\n",
    "\n",
    "## Tutorial 12 - Tracking\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
    "---\n",
    "* [Tracking](#-Tracking)\n",
    "    * [Tracking Challenges]()\n",
    "    * [Tracking as inference]()\n",
    "    * [Kalman Filter](#-Kalman-Filter)\n",
    "        * [One Dimensional Example]()\n",
    "        * [Multi-Dimensional Example]()\n",
    "* [Recommended Videos](#-Recommended-Videos)\n",
    "* [Credits](#-Credits)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# imports for the tutorial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "from IPython.display import Image,Video\n",
    "from IPython.lib.display import YouTubeVideo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <img src=\"https://img.icons8.com/cotton/64/000000/track-order.png\" style=\"height:50px;display:inline\"> Tracking\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tracking example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('SKXk6uB8348')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* <a href=\"https://github.com/ZidanMusk/experimenting-with-sort\">Source</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tracking Challenges\n",
    "---\n",
    "1. Hard to compute optical flow\n",
    "2. Object could be moving rapidly\n",
    "3. Errors would accumulate\n",
    "4. Occlusions, disoclutions\n",
    "5. Multiple objects tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Desired properties:\n",
    "\n",
    "* Real-Time\n",
    "* Coherent smooth trajectories\n",
    "\n",
    "Use dynamic modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tracking as Inference\n",
    "---\n",
    "* We start with a prediction that relies on the previous state $x_{t-1}$. Given the last state we have a belief/**prediction** that the next step $x_{t}$ will be close to the previous step (blue Gaussian).\n",
    "* Now, we take a **measurement**  $y_t$, suffering from some noise (orange Gaussian).\n",
    "* Using the measurment $y_t$ we can correct and **update** our prediction $x_{t}$ (grey Gaussian).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./assets/tut12__kal2.JPG\" width=\"600\">\n",
    "\n",
    "\n",
    "<a href=\"https://fr.mathworks.com/videos/understanding-kalman-filters-part-3-optimal-state-estimator--1490710645421.html\">Image Source</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Steps of Tracking\n",
    "* Prediction: We use the estimated state to predict the current state and uncertainty.\n",
    "\n",
    "$$P(X_t|Y_0=y_0,...,Y_{t-1}=y_{t-1})$$\n",
    "* Update: We use our sensors' observations to correct the predicted state and obtain a more accurate estimate.\n",
    "\n",
    "$$P(X_t|Y_0=y_0,...,Y_{t}=y_{t})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Simplification Assumptions:\n",
    "\n",
    "* The *dynamics model* is Markovian - describes the relationship between states $x_t$ and $x_{t-1}$, only the immediate past matters. $$P(X_t|X_0,...,X_{t-1}) = P(X_t|X_{t-1})$$\n",
    "    * This means that the next state only depends on the last state. The state also includes the velocity, and not only position. It is a dynamics model.\n",
    "* The *measurement model*, the measurment only depends on the current state - describes the relationship between the measurements $y_t$ and the state $x_t$ at time $t$. $$P(Y_t|X_0,Y_0,...,X_{t-1},Y_{t-1},X_{t}) = P(Y_t|X_{t})$$\n",
    "    * A bit suspicious assumption, how come the sensor noise is not estimated by using previous measurements? In more advanced algorithms, the past is also considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Graphical model:\n",
    "\n",
    "Note, we are changing the notations: $X_i->w_i$ are the states, and $Y_i->x_i$ are the measurments.\n",
    "\n",
    "<img src=\"./assets/tut12_kal3.JPG\" width=\"400\">\n",
    "\n",
    "* Image source - Prince 539\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Simplify Tracking Steps\n",
    "\n",
    "* Prediction\n",
    "    * Given: $P(w_{t-1}|x_0,...,x_{t-1})$ (our last state belief)\n",
    "    * Guess: $P(w_{t}|x_0,...,x_{t-1})$\n",
    "    \n",
    "Using the law total probability:\n",
    "\n",
    "<img src=\"./assets/tut12_kal5.JPG\" width=\"400\">\n",
    "\n",
    "Where $P(w_{t}|w_{t-1})$ is going to be our *dynamics model*.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Correction \n",
    "    * Given: $P(w_{t-1}|x_0,...,x_{t-1})$ and $x_t$, adding our last measurmant\n",
    "    * Compute: $P(w_{t}|x_0,...,x_{t-1},x_{t})$\n",
    "\n",
    "Using base rules:\n",
    "<img src=\"./assets/tut12_kal4.JPG\" width=\"400\">\n",
    "Where $P(x_{t}|w_{t})$ is going to be our *mesurment model*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Linear Dynamics Model\n",
    "\n",
    "The transformation is linear and the noise is Gaussian $$w_t \\sim N(\\mu_p + \\Psi w_{t-1},\\Sigma_p)$$\n",
    "$\\Psi\\in R^{D_w\\times D_w}$ is either a scalar or a matrix.\n",
    "\n",
    "#### Linear Measurment Model\n",
    "\n",
    "$$x_t \\sim N(\\mu_m +\\Phi w_{t},\\Sigma_m)$$\n",
    "\n",
    "$\\Phi \\in R^{D_x\\times D_w}$ is either a scalar or a matrix.\n",
    "\n",
    "$\\Psi,\\Phi,\\mu_p,\\mu_m,\\Sigma_p,\\Sigma_m$ are known and imply how our model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <img src=\"https://img.icons8.com/nolan/64/filter.png\" style=\"height:50px;display:inline\">  Kalman Filter\n",
    "---\n",
    "The Kalman filter is one of the most popular algorithms in data fusion. Invented in 1960 by Rudolph Kalman, it is now used in our phones or satellites for navigation and tracking. The most famous use of the filter was during the <a href=\"https://news.ycombinator.com/item?id=12043206\">Apollo 11 mission</a> to send and bring the crew back to the moon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Kalman filter is used for tracking a linear dynamical systems with additive normal noise. \n",
    "Therefore, for using Kalman filter we assume:\n",
    "* The uncertainty over the world state is described by a normal distribution.\n",
    "* The relationship between the measurements and the world is linear with additive normal noise.\n",
    "* The relationship between the state at adjacent times is also linear with additive normal noise.\n",
    "\n",
    "Gaussian modeling makes our model slightly simpler, as we only need to find the mean and the variance. Want to use non-Gaussian modeling? there are other filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./assets/tut12_kal1.PNG\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Given a state $w_{t-1}$ we predict $w_t$ and our uncertainty is reduced. \n",
    "* Then we take a new noisy measurement $x_t$ and correct our state. \n",
    "* Adding information (new measurment) can only **reduce** our initial guess uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Inference\n",
    "Our goal is to compute the posterior probability $P(w_t|x_0,...,x_t)$ over state $w_t$ given all the measurements so far.\n",
    "* Prediction\n",
    "<img src=\"./assets/tut12_kal6.JPG\" width=\"600\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Correction\n",
    "<img src=\"./assets/tut12_kal7.JPG\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* You can find the full explanation in Prince's book, chapter 19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Updates\n",
    "\n",
    "<img src=\"./assets/tut12_kal8.JPG\" width=\"500\">\n",
    "<img src=\"./assets/tut12_kal9.JPG\" width=\"600\">\n",
    "\n",
    "$K$ is usually known as **\"Kalman Gain\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice:\n",
    "* The Covariance prediction *always grows*.\n",
    "* The Covariance update can only get *smaller*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Prediction vs Correction:\n",
    "    * For a low measurment uncertanity (we know our measurments are precise): $\\Sigma_m = 0$ then $K={\\Phi}^{-1}$: $w_t$ depends only on the measurments. $$\\mu_t = K(x_t-\\mu_m), \\Sigma_t = 0$$\n",
    "    * For no prediction uncertanity (we know our predictions are precise): $\\Sigma_{+} = 0$ then $K=0$: $w_t$ depends only on the prediction. $$\\mu_t = \\mu_{+}, \\Sigma_t = \\Sigma_{+} =  0$$\n",
    "    * Generaly, low gain puts more weight to the prediction, and high Kalman gain puts more wights to the measurments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <img src=\"https://img.icons8.com/ios-filled/50/000000/example.png\" style=\"height:50px;display:inline\"> Examples\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One Dimensional Kalman Filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Let us write a code for the one-dimensional Kalman filters first. \n",
    "* Consider the case in which we measure the temperature from an erroneous thermometer.\n",
    "* The following are the measurements taken from an erroneous thermometer at different times, also we assume that we know that the actual temperature is 45 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "measurement = [45,48,49,41,42,60,46,47,42,46,47,41,40,43,45,46,43,45,46,\n",
    "               41,39,45,48,42,43,44,45,46,47,42,40,41,41,61,45,45,43,42,42,40]\n",
    "actual = 45\n",
    "# measurement = actual + np.random.randn(len(measurement)) * 5 # tet for signal+noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us plot these measurements using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Noisy Measurements and actual measurements')\n",
    "plt.ylabel('Temperature in degree celsius')\n",
    "plt.xlabel('Time')\n",
    "plt.plot(measurement,label = 'Measurements from the thermometer')\n",
    "# plt.hold(True)\n",
    "plt.axhline(y=actual, color='r', linestyle='-',label = 'Actual Temperature')\n",
    "plt.axis([0,len(measurement)-1,0,90])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let’s run the code for the Kalman Filtering process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "initial_estimate = 60 # actually this can be anything \n",
    "initial_error_estimate = 2\n",
    "error_in_measurement = 4\n",
    "current_estimate = initial_estimate\n",
    "current_error_estimate = initial_error_estimate\n",
    "kalman_output_list = []\n",
    "kalman_output_list.append(initial_estimate)\n",
    "for i in range(len(measurement)):\n",
    "    \n",
    "    \n",
    "  ####################################\n",
    "  # Step 1 , calculate the Kalman Gain.\n",
    "  \n",
    "    kalman_gain = (current_error_estimate)/(current_error_estimate + error_in_measurement)\n",
    "  ####################################\n",
    "  # Step 2 , calculate the estimate at time 't' from the measurement and estimate at time 't-1'\n",
    "    kalman_output = (current_estimate + (kalman_gain)*(measurement[i] - current_estimate))\n",
    "\n",
    "    kalman_output_list.append(kalman_output)\n",
    "    \n",
    "    \n",
    "  ####################################\n",
    "  # Step 3 , calculate the error estimate at time 't'\n",
    "    new_error_estimate = (1-kalman_gain)*(current_error_estimate)\n",
    "    \n",
    "    \n",
    "  ##############################################\n",
    "  # make the previous variables the current variables for the next iteration\n",
    "    current_estimate = kalman_output\n",
    "    current_error_estimate = new_error_estimate\n",
    "  ##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we have the Kalman Filters output with us.\n",
    "\n",
    "Lets finally plot them and check our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('One Dimensional Kalman Filter Output')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature in degrees')\n",
    "plt.plot(measurement,label = 'Measuerements from the thermometer')\n",
    "plt.axhline(y=actual, color='r', linestyle='-',label = 'Actual Temparature')\n",
    "# plt.hold(True)\n",
    "plt.plot(kalman_output_list,'-g',label = 'kalman output')\n",
    "plt.axis([0,len(measurement)-1,0,110])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-Dimensional Case\n",
    "\n",
    "<img src=\"./assets/tut12_balltracking.PNG\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following code demonstrates tracking of a ball,rolling across the scene with the help of Kalman Filter algorithm used for object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "file = './assets/singleball.mov'\n",
    "cap = cv2.VideoCapture(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Video('./assets/singleball.mov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Background Subtraction \n",
    "* Background subtraction (BS) is a common and widely used technique for generating a foreground mask (namely, a binary image containing the pixels belonging to moving objects in the scene) by using static cameras.\n",
    "* As the name suggests, BS calculates the foreground mask performing a subtraction between the current frame and a background model, containing the static part of the scene or, more in general, everything that can be considered as background given the characteristics of the observed scene.\n",
    "\n",
    "<img src=\"./assets/tut12_background.JPG\" width=\"600\">\n",
    "<a href=\"https://docs.opencv.org/master/d1/dc5/tutorial_background_subtraction.html\">Image source\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* In this tutorial, we use the mixture of Gaussians (MOG) as done in the GrabCut algorithm.\n",
    "* This time, the background is learned from a video, and there is no user intervention.\n",
    "* You can use any segmentation method to extract the desired object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Measuring Ball Location\n",
    "\n",
    "For each frame:\n",
    "1. Learn to substruct background using a mixture of Gaussians MOG (slightly similar to Grab-Cut) - improve during the process.\n",
    "2. Extract contours\n",
    "3. Add location measurement if exists else set to $[-1,-1]$ (out of range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.hold(True)\n",
    "plt.axis([0,cap.get(3),cap.get(4),0])\n",
    "numframes = cap.get(4)\n",
    "count = 0   # for counting the number of frames\n",
    "cap = cv2.VideoCapture(file)\n",
    "bgs = cv2.createBackgroundSubtractorMOG2()\n",
    "# Let us make an array for storing the values of (x,y) co-ordinates of the ball\n",
    "# If the ball is not visible in the frame then keep that row as [-1.0,-1.0]\n",
    "# Thus lets initialize the array with rows of [-1.0 , -1.0]\n",
    "measuredTrack = np.zeros((int(numframes), 2))-1\n",
    "while count < (numframes):\n",
    "    count += 1\n",
    "    ret, img2 = cap.read()\n",
    "#     cv2.imshow(\"Video\",img2)\n",
    "#     cv2.namedWindow(\"Video\",cv2.WINDOW_NORMAL)\n",
    "    foremat = bgs.apply(img2, learningRate = 0.01)\n",
    "#     cv2.waitKey(20)\n",
    "    ret, thresh = cv2.threshold(foremat, 220, 255, 0)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #print(len(contours))  ## This prints the number of contours (foreground objects detected)\n",
    "    if len(contours) > 0:\n",
    "        for i in range(len(contours)):\n",
    "            area = cv2.contourArea(contours[i])  ## Calculates the Area of contours\n",
    "            if area > 100: ## We check this because the area of the ball is bigger than 100 and we want to plot that only\n",
    "                m = np.mean(contours[i],axis=0) ### mean is taken for finding the centre of the contour (ball in this case)\n",
    "                measuredTrack[count-1,:] = m[0] \n",
    "                plt.plot(m[0,0], m[0,1], 'xr')\n",
    "#     cv2.imshow('Foreground',foremat)\n",
    "#     cv2.namedWindow(\"Foreground\",cv2.WINDOW_NORMAL)\n",
    "#     cv2.waitKey(80)\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "# print(measuredTrack)\n",
    "### save the trajectory of the ball in a numpy file , so that it can be used\n",
    "### later to be passed as an input to the Kalman Filter process.\n",
    "np.save(\"ballTrajectory\", measuredTrack)   \n",
    "plt.axis((0,480,360,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The above loop iterates over all frames of the video sequence.\n",
    "\n",
    "* Each frame is plotted to the OpenCV figure video. Then the `apply()` method of the background subtractor instance is called, this method returns a foreground mask for the current frame.\n",
    "\n",
    "* By applying a threshold to the foreground mask it is converted into a binary image, containing 1 at all pixels which belong to the foreground and 0 at all pixels belonging to background. An area of connected foreground pixels is a foreground object.\n",
    "\n",
    "* The contours of foreground objects can be determined by applying OpenCV’s `findContours()` function. In general there can exist more than one foreground objects and corresponding contours in a frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Explanation of the Code\n",
    "\n",
    "1) The centroid of the contour is assumed to be the location of the foreground object.\n",
    "\n",
    "2) This location is tracked for each frame. The location is plotted into the matplotlib figure.\n",
    "\n",
    "3) Moreover, for each frame the location of the tracked object is stored in the numpy array `measuredTrack`.\n",
    "\n",
    "4) Finally the numpy array `measuredTrack` is stored to a file. The contents of this file (i.e. the measured track) constitute the input for the Kalman Filter. The Kalman Filter is implemented in another Python module (see Kalman Filter ) and provides a more accurate track of the moving object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **The track measured above shall be refined by Kalman filtering.** \n",
    "* Even though a Kalman Filter is implemented in OpenCV, we apply the Kalman Filter module `pykalman` due to its better documentation.\n",
    "\n",
    "* So lets install `pykalman` first. Import the ”KalmanFilter” library from this amazing module. And, load the saved “ballTrajectory.npy” file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "Measured = np.load(\"ballTrajectory.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Remove the first part of the video from the measured array when the ball is not present in the video.\n",
    "* So we need to remove all the rows of $[ -1.0,-1.0 ]$ untill the first measurement is recorded (the time when the ball enters the video).\n",
    "* If you looked closely, you probably have noticed that the ball enters in the video sometime after the video starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    if Measured[0,0]==-1.:\n",
    "        Measured=np.delete(Measured,0,0)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "numMeas = Measured.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* However, as you can clearly see there are some parts of this array still have the $[-1.0 , -1.0]$ rows left.\n",
    "* These indicate the parts of the video where the ball was inside the box and also the parts of the video after the ball is gone completely out of the vision.\n",
    "* By applying Numpy Masked Arrays, these positions without measurement can be particullarly marked and the following Kalman Filter module is able to interprete these positions as **missing-measurement position**.\n",
    "* Thus, at these positions we can use the help of the Kalman FIlter algorithm to predict the position of the ball even when it is behind the box or even out of the video completely !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "MarkedMeasure = np.ma.masked_less(Measured, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this demonstration the state is modeled as a *vector*, containing the variables:\n",
    "\n",
    "* x-coordinate of current position: $x$\n",
    "\n",
    "* y-coordinate of current position: $y$\n",
    "\n",
    "* current speed in x-direction: $vx$\n",
    "\n",
    "* current speed in y-direction: $vy$\n",
    "\n",
    "The measured parameters are $x$ and $y$. Thus the transition matrix (process model) and the observation matrix (measurement model) are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Transition_Matrix = [[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]]  # Psi matrix\n",
    "Observation_Matrix = [[1, 0, 0, 0], [0, 1, 0, 0]] # Phi matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Besides these two models the Kalman Filter requires:\n",
    "\n",
    "1. An initial state, defined by `xinit,yinit,vxinit,vyinit`.\n",
    "\n",
    "2. An initial state covariance `initstatecovariance`, which describes the certainty of the initial state.\n",
    "\n",
    "3. A transition covariance, which describes the certainty of the process model.\n",
    "\n",
    "4. An observation covariance, which describes the certainty of the measurement model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "xinit = MarkedMeasure[0,0] ## First Measurement of x-coord\n",
    "yinit = MarkedMeasure[0,1] ## First Measurement of y-coord\n",
    "vxinit = MarkedMeasure[1,0] - MarkedMeasure[0,0] ## as v = (d_1 - d_0)/(time)\n",
    "vyinit = MarkedMeasure[1,1] - MarkedMeasure[0,1] \n",
    "initstate = [xinit, yinit, vxinit, vyinit]\n",
    "initcovariance = 1.0e-3 * np.eye(4) \n",
    "transistionCov = 1.0e-4 * np.eye(4)\n",
    "observationCov = 1.0e-1 * np.eye(2)\n",
    "kf = KalmanFilter(transition_matrices=Transition_Matrix,\n",
    "                  observation_matrices =Observation_Matrix,\n",
    "                  initial_state_mean=initstate,\n",
    "                  initial_state_covariance=initcovariance,\n",
    "                  transition_covariance=transistionCov,\n",
    "                  observation_covariance=observationCov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By calling the `filter()` method of the KalmanFilter object, the track (`filtered_mean_state`) and its certainty in form of `filtered_state_covariances` are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(filtered_state_means, filtered_state_covariances) = kf.filter(MarkedMeasure)\n",
    "plt.plot(MarkedMeasure[:,0] ,MarkedMeasure[:,1], 'xr', label='measured')\n",
    "plt.axis([0,520,360,0])\n",
    "# plt.hold(True)\n",
    "plt.plot(filtered_state_means[:,0],filtered_state_means[:,1],'ob',label='kalman output')\n",
    "# plt.hold(True)\n",
    "plt.legend(loc=3)\n",
    "plt.title(\"Constant Velocity Kalman Filter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problems with the Kalman filter\n",
    "\n",
    "* It requires the temporal and measurement equations to be linear.\n",
    "* It assumes that the marginal posterior is unimodal and can be well captured by a mean and covariance; hence, it can only ever have one hypothesis about the position of the object\n",
    "\n",
    "Can be solved using *Extended Kalman filter* and the *unscented Kalman filter*, both allow nonlinear state update and measurement equations. \n",
    "\n",
    "*Particle filtering* abandons the use of the normal distribution and describes the state as a complex multi-modal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/video-playlist.png\" style=\"height:50px;display:inline\"> Recommended Videos\n",
    "---\n",
    "#### <img src=\"https://img.icons8.com/cute-clipart/64/000000/warning-shield.png\" style=\"height:30px;display:inline\"> Warning!\n",
    "* These videos do not replace the lectures and tutorials.\n",
    "* Please use these to get a better understanding of the material, and not as an alternative to the written material.\n",
    "\n",
    "#### Video By Subject\n",
    "* Kalman Filter by Michel va Biezen - https://www.youtube.com/watch?v=CaCcOwJPytQ&list=PLX2gX-ftPVXU3oUFNATxGXY90AULiqnWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
    "----\n",
    "* Towardsdatascience\n",
    "    * https://towardsdatascience.com/computer-vision-for-tracking-8220759eee85 - Jeremy Cohen\n",
    "    * https://towardsdatascience.com/sensor-fusion-90135614fde6 - Jeremy Cohen\n",
    "    \n",
    "    * https://towardsdatascience.com/optimal-estimation-algorithms-kalman-and-particle-filters-be62dcb5e83 - Pier Paolo Ippolito\n",
    "    * https://towardsdatascience.com/particle-filter-a-hero-in-the-world-of-non-linearity-and-non-gaussian-6d8947f4a3dc\n",
    "    \n",
    "    \n",
    "* Chapter 11. Tutorial: The Kalman Filter, Tony Lacey - http://web.mit.edu/kirtley/kirtley/binlustuff/literature/control/Kalman%20filter.pdf \n",
    "* Kalman filter code and tutorial source - \n",
    "    * https://iitmcvg.github.io/summer_school/Session4/\n",
    "    * https://www.hdm-stuttgart.de/~maucher/Python/ComputerVision/html/Tracking.html\n",
    "* Prince, chapter 19\n",
    "\n",
    "* Icons from <a href=\"https://icons8.com/\">Icon8.com</a> - https://icons8.com\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
